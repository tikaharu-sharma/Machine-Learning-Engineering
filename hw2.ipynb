{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, email and UFID.\n",
    "Please do not modify instruction cells or any cells with automated tests (marked with `[ASSERTS]`). Note: you can add new cells if you need them, but answers must be in the cells with `YOUR CODE HERE` or \"YOUR ANSWER HERE\" comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d32c3222b2442d52b065e77cd55ac2f",
     "grade": false,
     "grade_id": "homework-preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Homework 2: Regression and Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5658c9a4ed21f362746fdaeb7fb21351",
     "grade": false,
     "grade_id": "preamble-name",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Preamble: Write your Name, Email and UFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac6c2934a26e1ec9725344dae3cb163",
     "grade": false,
     "grade_id": "name-email-ufid",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework 2 -- name: Tikaharu Sharma, email: tikaharusharma@ufl.edu, UFID: 73535666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = 'Tikaharu Sharma'\n",
    "EMAIL = 'tikaharusharma@ufl.edu'\n",
    "UFID = 73535666\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print('Homework 2 -- name: {}, email: {}, UFID: {}\\n'.format(NAME, EMAIL, UFID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c41a13a5f6e2fa1b47621d28e926c2cf",
     "grade": true,
     "grade_id": "name-email-ufid-asserts",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that your name, email, and UFID is filled in.\"\"\"\n",
    "assert NAME != '' and NAME != 'Your name here.' and len(NAME) > 3\n",
    "assert EMAIL != '' and EMAIL != 'Your email here.' and len(EMAIL) > 7\n",
    "assert type(UFID) == int and UFID != 12345678 and UFID >= 10000000 and UFID <= 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b4f30c4bbc2f9927b1410eeb1f001b3",
     "grade": false,
     "grade_id": "preamble-academic-integrity",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Academic Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99184dabc791053131230787b9f498b8",
     "grade": false,
     "grade_id": "preamble-academic-integrity-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <span style=\"color:red;\">This is an individual assignment. Academic integrity violations (i.e., cheating, plagiarism) will be reported to SCCR!</span><br/>\n",
    "#### The official CISE policy recommended for such offenses is a course grade of E. Additional sanctions may be imposed by SCCR such as marks on your permanent educational transcripts, dismissal or expulsion.\n",
    "#### Reminder of the Honor Pledge: On all work submitted for credit by Students at the University of Florida, the following pledge is either required or implied: *\"On my honor, I have neither given nor received unauthorized aid in doing this assignment.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8d2452e1d9f6d547eae6447b7ca369",
     "grade": false,
     "grade_id": "cell-preamble-academic-integrity-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Acknowledgement: Do you acknowledge and understand the academic integrity warning above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89bc9ed2e09cb9069b92dc24a3bc081a",
     "grade": false,
     "grade_id": "academic-integrity",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "academic_integrity_acknowledgement = True\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d6eb103ab3a60e964c163468d9aa7a",
     "grade": true,
     "grade_id": "academic-integrity-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that you acknowledge the academic integrity warning, you understand it and have been reminded of the UF Honor Pledge.\"\"\"\n",
    "assert academic_integrity_acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f73a6c8f764fdac6667f0157a544866",
     "grade": false,
     "grade_id": "task1-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 1] (20 points) Loading and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0290223a82f05fc5d6606de4df6e43e",
     "grade": false,
     "grade_id": "task1-instructb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1] We will use the Bike Sharing dataset (hourly). A version of this dataset is included in the homework handout archive.\n",
    "### This dataset contains features of users bike sharing/rental on an hourly basis.\n",
    "### The task is to predict how many users are sharing/renting a bike.\n",
    "### You will load the data and preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e0c6343e3d6ae8ef5568125e9de64f",
     "grade": false,
     "grade_id": "task1-instructc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The following cell's code (import statements etc.) is provided for you and you should not need to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119d3a62a34e7425f288493659994237",
     "grade": false,
     "grade_id": "task1-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.10.19 (main, Oct 21 2025, 16:37:10) [Clang 20.1.8 ]\n",
      "### NumPy version: 2.2.5\n",
      "### Scikit-learn version: 1.7.2\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print('### NumPy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "def var_exists(var_name):\n",
    "    return (var_name in globals() or var_name in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cc6d3b909b447a027649ca1d83883d9",
     "grade": false,
     "grade_id": "seed_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### This is the seed we will use, do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d04202483cecc7aa53f8ad98656ef967",
     "grade": false,
     "grade_id": "setting_seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [16, 2, 2] # proportions for train - val - test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d746a78509c270bb1f51eff6a455a1f6",
     "grade": true,
     "grade_id": "seed_checking",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check seed. \"\"\"\n",
    "assert seed == 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26690ee65de9a82553bc05a151c027e",
     "grade": false,
     "grade_id": "task1-instructd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading data (set the path correctly so it runs on your machine --- don't submit the data file with your notebook).\n",
    "#### Note: this dataset has missing values (artificially introduced), which you'll need to fill in before you can train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "424a20cc93e7cd774f4c8c7ca4e10b8e",
     "grade": false,
     "grade_id": "task1-loaddata",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in the path to the directory where 'bikesharehour.csv.gz' is located.\n",
    "\"\"\"\n",
    "data_root = 'data' #put the path here\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0108c0dd4a83a9bfa362cc0f065ee631",
     "grade": true,
     "grade_id": "task1-loaddata-test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      16320 non-null  float64\n",
      " 1   year        16231 non-null  float64\n",
      " 2   month       16304 non-null  float64\n",
      " 3   hour        16254 non-null  float64\n",
      " 4   holiday     16276 non-null  float64\n",
      " 5   weekday     16282 non-null  float64\n",
      " 6   workingday  16297 non-null  float64\n",
      " 7   weathersit  16324 non-null  float64\n",
      " 8   temp        16242 non-null  float64\n",
      " 9   atemp       16271 non-null  float64\n",
      " 10  hum         16252 non-null  float64\n",
      " 11  windspeed   16281 non-null  float64\n",
      " 12  registered  16244 non-null  float64\n",
      " 13  nsqrtc      16261 non-null  float64\n",
      " 14  count       17379 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_fp = os.path.join(data_root, 'bikesharehour.csv.gz')\n",
    "assert os.path.exists(dataset_fp), f\"Dataset not found ({dataset_fp})!\"\n",
    "df = pd.read_csv(dataset_fp, compression='gzip', header=0, na_values='?')\n",
    "\n",
    "# Check that we loaded the data as expected\n",
    "df_expected_shape = (17379, 15)\n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7eeb7ee17ac4b775a371e7bbf65f324",
     "grade": false,
     "grade_id": "task1a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1a] (5 points) Show the first 9 rows of the dataframe df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c184f6d42bf2f1fd7c9d09dcb513c987",
     "grade": false,
     "grade_id": "task1a_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>registered</th>\n",
       "      <th>nsqrtc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  month  hour  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0     1.0   0.0    NaN   0.0      0.0      6.0         0.0         1.0   NaN   \n",
       "1     1.0   0.0    NaN   1.0      0.0      6.0         0.0         1.0   NaN   \n",
       "2     1.0   0.0    1.0   2.0      0.0      6.0         0.0         1.0   0.0   \n",
       "3     1.0   0.0    1.0   3.0      0.0      6.0         0.0         1.0   0.0   \n",
       "4     1.0   0.0    1.0   4.0      NaN      6.0         0.0         1.0   0.0   \n",
       "5     1.0   0.0    1.0   5.0      0.0      6.0         0.0         2.0   0.0   \n",
       "6     1.0   0.0    1.0   6.0      0.0      6.0         0.0         1.0   0.0   \n",
       "7     1.0   0.0    1.0   7.0      0.0      6.0         0.0         1.0   0.0   \n",
       "8     1.0   0.0    1.0   8.0      0.0      6.0         0.0         1.0   0.0   \n",
       "\n",
       "   atemp  hum  windspeed  registered  nsqrtc  count  \n",
       "0    0.0  0.0        0.0        14.0   -51.0     16  \n",
       "1    0.0  0.0        0.0        32.0    -8.0     40  \n",
       "2    0.0  0.0        0.0        27.0   -71.0     32  \n",
       "3    0.0  0.0        0.0        10.0    -5.0     13  \n",
       "4    0.0  0.0        0.0         1.0     0.0      1  \n",
       "5    0.0  0.0        1.0         1.0     0.0      1  \n",
       "6    0.0  0.0        0.0         0.0     4.0      2  \n",
       "7    NaN  0.0        0.0         2.0    -3.0      3  \n",
       "8    0.0  0.0        0.0         7.0     3.0      8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here.\n",
    "\"\"\"\n",
    "## what does the data look like?\n",
    "# YOUR CODE HERE\n",
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef256ef6755e83f93cfc89ed965e27f",
     "grade": true,
     "grade_id": "task1-features",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered', 'nsqrtc']\n",
      "target: count\n"
     ]
    }
   ],
   "source": [
    "# grab all the data as a numpy matrix\n",
    "all_xy = df.to_numpy()\n",
    "\n",
    "col_names = [c for c in df.columns]\n",
    "features = col_names[:-1]\n",
    "target = col_names[-1]\n",
    "\n",
    "# what are the features and what is the target?\n",
    "print(f\"features: {features}\")\n",
    "print(f\"target: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed63e4914913eddf712ab1a267b2b756",
     "grade": false,
     "grade_id": "task1b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1b] (5 points) Answer the following questions by setting variables (hardcoding or computing the answer) from 'all_xy'. \n",
    "## (1) If we do supervised learning to predict 'count' based on our features is this classification or regression? (Set the corresponding variable to True.) \n",
    "## (2) How many NaNs are there in columns 'holiday','temp', and 'count'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e10a22f5cd4a405b28c06b0d1bafc2a",
     "grade": false,
     "grade_id": "task1b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here and set the variables appropriately.\"\"\"\n",
    "\n",
    "classification = False\n",
    "regression = True\n",
    "\n",
    "# Compute NaN counts from the dataframe `df` (available in the notebook scope)\n",
    "holiday_NaNs = int(df['holiday'].isna().sum())\n",
    "temp_NaNs = int(df['temp'].isna().sum())\n",
    "count_NaNs = int(df['count'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc7d99202916a313b25fcfe853eabb82",
     "grade": true,
     "grade_id": "task1b_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1b completed. \"\"\"\n",
    "\n",
    "assert var_exists('classification') and var_exists('regression') and classification != regression\n",
    "assert var_exists('holiday_NaNs') and holiday_NaNs >= 0\n",
    "assert var_exists('temp_NaNs') and temp_NaNs >= 0\n",
    "assert var_exists('count_NaNs') and count_NaNs >= 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3f1a8772ba51267b07033f0557d23",
     "grade": false,
     "grade_id": "task1c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1c] (5 points) Let's impute the missing values! Use Scikit-learn's SimpleImputer to replace all NaNs in 'all_xy' with the *most frequent* value in each column. Use copy=True and store the results in 'all_xy_noNaNs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ed4013643fc31a30fb6b4c395a42fa3",
     "grade": false,
     "grade_id": "task1c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "from sklearn.impute import SimpleImputer\n",
    "# YOUR CODE HERE\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\", copy=True)\n",
    "all_xy_noNaNs = imputer.fit_transform(all_xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4efd8da58007234bfbad9d825036ade0",
     "grade": true,
     "grade_id": "task1c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1c completed. \"\"\"\n",
    "\n",
    "assert var_exists('all_xy_noNaNs') and all_xy_noNaNs.shape == df_expected_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1024eb6bf3e5eb85b038955feda0cbdc",
     "grade": false,
     "grade_id": "task1d-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1d] (5 points) Min-max normalize the features (to [0,1] range) using sklearn's MinMaxScaler. Store the results into 'scaled_all_x'. Then split the data into train, val, test according to the proportion in prop_vec using sklearn's train_test split. Store the results into 'train_x', 'train_y', 'test_x', 'test_y', 'val_x', 'val_y'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33549a9e16d2ce1ac32610f23d0c8d16",
     "grade": false,
     "grade_id": "task1d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [ASSERTS] Check 1d completed. '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "all_x = all_xy_noNaNs[:, :-1]\n",
    "all_y = all_xy_noNaNs[:, -1]\n",
    "scaled_all_x = scaler.fit_transform(all_x)\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(scaled_all_x, all_y, test_size=0.2, random_state=seed)\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.5, random_state=seed)\n",
    "\n",
    "\"\"\" [ASSERTS] Check 1d completed. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4391b903af2254d5c08592beb7f674",
     "grade": true,
     "grade_id": "task1d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 1d. \"\"\"\n",
    "assert var_exists('scaled_all_x')\n",
    "assert var_exists('train_x') and var_exists('train_y') and train_x.shape[0] == train_y.shape[0]\n",
    "assert var_exists('val_x') and var_exists('val_y') and val_x.shape[0] == val_y.shape[0]\n",
    "assert var_exists('test_x') and var_exists('test_y') and test_x.shape[0] == test_y.shape[0]\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)\n",
    "assert np.amin(train_x) >= 0.0 and np.amax(train_x) <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d244ec65844cdeb839f49b48a142b738",
     "grade": false,
     "grade_id": "task2_instructa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2] (30 points) Evaluating and training linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "468d738a8668ff10566793c58904bae5",
     "grade": false,
     "grade_id": "task2a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2a] (5 points) Fill in the code to calculate and return the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22503202d8c12f1f4b5e7be3afd66af3",
     "grade": false,
     "grade_id": "task2a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in your code below (~5-7 lines).\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def r2_mse_mae_eval(model, tr_x, tr_y, v_x, v_y, pref='', verb=True):\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # R^2 the coefficient of determination\n",
    "    # YOUR CODE HERE\n",
    "    train_r2 = model.score(tr_x, tr_y)\n",
    "    val_r2 = model.score(v_x, v_y)\n",
    "    \n",
    "    if verb:\n",
    "        print(f\"{pref}Train R^2: {train_r2:.3f}, Val  R^2: {val_r2:.3f}\")\n",
    "\n",
    "    train_pred = model.predict(tr_x)\n",
    "    val_pred = model.predict(v_x)\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_mse = mean_squared_error(train_pred, tr_y)\n",
    "    val_mse = mean_squared_error(val_pred, v_y)\n",
    "\n",
    "    if verb:\n",
    "        print(f\"{pref}Train MSE: {train_mse:.3f}, Val MSE: {val_mse:.3f}\")\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_mae = mean_absolute_error(train_pred, tr_y)\n",
    "    val_mae = mean_absolute_error(val_pred, v_y)\n",
    "\n",
    "    if verb:\n",
    "        print(f\"{pref}Train MAE: {train_mae:.3f}, Val MAE: {val_mae:.3f}\")\n",
    "\n",
    "    return train_r2, val_r2, train_mse, val_mse, train_mae, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18b3441ddafcf1fd86c8562815958ce4",
     "grade": true,
     "grade_id": "task2a_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 2a. \"\"\"\n",
    "assert var_exists('r2_mse_mae_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19220fc3ba3d815f8fbcb28390c0ccf7",
     "grade": false,
     "grade_id": "task2b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] (5 points) Train a linear regression model using the default (hyper)parameters. Call the resulting trained model 'lrmodel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dfe0fdc4f5aeae197e64d44281a5e16",
     "grade": false,
     "grade_id": "task2b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LinearRegression] Train R^2: 0.841, Val  R^2: 0.845\n",
      "[LinearRegression] Train MSE: 5268.343, Val MSE: 5184.028\n",
      "[LinearRegression] Train MAE: 39.637, Val MAE: 38.503\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~1-2 lines).\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# YOUR CODE HERE\n",
    "lrmodel = LinearRegression()\n",
    "lrmodel.fit(train_x, train_y)\n",
    "\n",
    "_ = r2_mse_mae_eval(lrmodel, train_x, train_y, val_x, val_y, pref='[{}] '.format(lrmodel.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ff682ab212149d93df0732df296ce5",
     "grade": false,
     "grade_id": "task2b-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] How good is that model? (A few sentences is fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f28a10e885076e373cd3240aae6b68d",
     "grade": true,
     "grade_id": "cell-task2b_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "# The linear regression model performs reasonably well: validation R^2 is high and close to training R^2,\n",
    "# and validation MSE/MAE are only slightly worse than training, which suggests limited overfitting\n",
    "# and decent generalization. It is not perfect, though, so some nonlinear structure likely remains unmodeled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c931713a37b5131c09838b45911da0e8",
     "grade": false,
     "grade_id": "task2c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2c] (5 points) Fill in the code below to setup a grid search. Concatenate the train and val sets into 'search_x' and 'search_y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69f5b6ec43a8b27e75e319bfb9366627",
     "grade": false,
     "grade_id": "task2c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## some code to do a grid search and automatically train & evaluate the model with the best hyperparams.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def do_grid_search(model, param_grid, x, y):\n",
    "    gs = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error')\n",
    "    gs_res = gs.fit(x, y)\n",
    "    return  gs_res.best_params_\n",
    "\n",
    "\n",
    "def search_train_eval(model, param_grid, tr_x=train_x, tr_y=train_y, v_x=val_x, v_y=val_y):\n",
    "\n",
    "    \"\"\"Put your code here (~2-3 lines). Concatenate the train and val sets into 'search_x' and 'search_y'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    search_x = np.concatenate((tr_x, v_x), axis=0)\n",
    "    search_y = np.concatenate((tr_y, v_y), axis=0)\n",
    "    \n",
    "    hyperparams = do_grid_search(model, param_grid, search_x, search_y)\n",
    "    \n",
    "    class_obj = type(model)\n",
    "    m = class_obj(**hyperparams).fit(tr_x, tr_y)\n",
    "    \n",
    "    cn = str(class_obj).split(\"'\")[1]\n",
    "    cn = cn.split('.')[-1]\n",
    "    print(f\"{cn}({hyperparams})\")\n",
    "\n",
    "    r2_mse_mae_eval(m, tr_x, tr_y, v_x, v_y, pref='\\t')\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48519e6f82d7736ba46225ca36362d92",
     "grade": true,
     "grade_id": "task2c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2c. \"\"\"\n",
    "assert var_exists('search_train_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd2d328fca71fef762e80afcb4c533e",
     "grade": false,
     "grade_id": "task2d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2d] (10 points) Take a look at the code of search_train_eval() and do_grid_search(). Answer the following questions: \n",
    "### 1. Can you do LAD regression with sklearn? Why or why not? (Justify your answer.) Hint: take a look at the sklearn documentation and the course slides.\n",
    "### 2. Why is the scoring function for the grid search 'neg_mean_squared_error' (as opposed to 'mean_squared_error')? \n",
    "### 3. Why is it okay to do the search over search_x and search_y which are the concatenation of the train and 'validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72e30d480e9d39db7c1b99aa78c2dbc9",
     "grade": true,
     "grade_id": "task2d_answer",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "### Hint: take a look at the documentation of scikit-learn and think.\n",
    "## Answer: \n",
    "# 1. We can do LAD regression with sklearn but not with LinearRegression or Ridge. LinearRegression optimize L2\n",
    "# loss, not L1 absolute loss. The most direct way to achieve LAD regression within scikit-learn is by using the \n",
    "# QuantileRegressor class and setting the quantile parameter to 0.5. \n",
    "# \n",
    "# 2. GridSearchCV always maximizes its scoring metric. MSE should be minimized, so sklearn\n",
    "# uses 'neg_mean_squared_error' so \"larger is better\" still works (less MSE -> less negative -> higher score).\n",
    "#\n",
    "# 3. GridSearchCV does its own internal cross-validation splits on the data, so it is okay to search over \n",
    "# search_x and search_y.\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64460c67c3a177ebf1ab32de263afbc6",
     "grade": false,
     "grade_id": "task2e_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2e] (5 points) Write the code below to do a grid search on a LassoLars model. Call the resulting model 'lassolars_model'. Be sure to tune the regularization constant and 'fit_intercept'. Make sure training converges and that you set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af01b53b3bacacf8b6212b96621717c2",
     "grade": false,
     "grade_id": "task2e_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLars({'alpha': 0.01, 'fit_intercept': True})\n",
      "\tTrain R^2: 0.841, Val  R^2: 0.845\n",
      "\tTrain MSE: 5268.786, Val MSE: 5184.698\n",
      "\tTrain MAE: 39.630, Val MAE: 38.497\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LassoLars\n",
    "\n",
    "param_grid = {'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1.0], 'fit_intercept': [True, False]}\n",
    "lassolars_model = search_train_eval(LassoLars(max_iter=5000, random_state=seed), param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4e8cf326726c6095e9cfb210218ede0",
     "grade": true,
     "grade_id": "task2e_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2e. \"\"\"\n",
    "assert var_exists('lassolars_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad6f73eba9ec23c4ffb8c2f3c9b79b1a",
     "grade": false,
     "grade_id": "task3-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3] (25 points) Let's train polynomial regression models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fb5dfae82b37f31d9212710d252b6cb",
     "grade": false,
     "grade_id": "task3a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3a] (15 points) Use PolynomialFeatures to create a version of the data with all features of degree 3. Follow the provided instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3de785d8bb3ca7ddc296eb8b7968897",
     "grade": false,
     "grade_id": "task3a-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge({'alpha': 1.0, 'fit_intercept': True})\n",
      "\tTrain R^2: 0.841, Val  R^2: 0.845\n",
      "\tTrain MSE: 5268.636, Val MSE: 5183.663\n",
      "\tTrain MAE: 39.706, Val MAE: 38.561\n",
      "[LinearRegression PF] Train R^2: 0.942, Val  R^2: 0.923\n",
      "[LinearRegression PF] Train MSE: 1926.635, Val MSE: 2570.585\n",
      "[LinearRegression PF] Train MAE: 22.472, Val MAE: 24.583\n",
      "Ridge({'alpha': 1.0, 'fit_intercept': False})\n",
      "\tTrain R^2: 0.902, Val  R^2: 0.896\n",
      "\tTrain MSE: 3259.995, Val MSE: 3488.906\n",
      "\tTrain MAE: 29.904, Val MAE: 30.981\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~10-15 lines).\n",
    "    1. Use PolynomialFeatures to create a version of the data with all features of degree 3. Make sure to allow interactions (interaction_only=False) and set include_bias=False.\n",
    "    Store the result in 'all_x_pf'. Ensure that you make a copy of the original data and you use the scaled features ('scaled_all_x')!\n",
    "    2. Split the data ('all_x_pf') into train-val-test using proportion from 'prop_vec' and save the result as 'train_{x,y}_pf', 'val_{x,y}_pf', and 'test_{x,y}_pf'.\n",
    "    3. Train three models for comparison. \n",
    "        (a) The first is a ridge regression model 'ridge' on the original scaled data (no polynomial features) where you tuned the hyperparameters.\n",
    "        (b) The second is a linear regression model 'lr_pf' on the polynomial features data.\n",
    "        (c) The third is a regularized \"linear\" model (ridge regression) on the polynomial features data where you tuned the hyperparameters (including regularization constant ensuring alpha >= 1.0).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polyf = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "all_x_pf = polyf.fit_transform(scaled_all_x.copy())\n",
    "\n",
    "train_x_pf, temp_x_pf, train_y_pf, temp_y_pf = train_test_split(\n",
    "    all_x_pf, all_y, test_size=(prop_vec[1] + prop_vec[2]) / sum(prop_vec), random_state=seed\n",
    ")\n",
    "val_x_pf, test_x_pf, val_y_pf, test_y_pf = train_test_split(\n",
    "    temp_x_pf, temp_y_pf, test_size=prop_vec[2] / (prop_vec[1] + prop_vec[2]), random_state=seed\n",
    ")\n",
    "\n",
    "ridge_grid = {\"alpha\": [0.01, 0.1, 1.0, 10.0, 100.0], \"fit_intercept\": [True, False]}\n",
    "ridge_nopf = search_train_eval(Ridge(random_state=seed), ridge_grid)\n",
    "\n",
    "lr_pf = LinearRegression().fit(train_x_pf, train_y_pf)\n",
    "_ = r2_mse_mae_eval(lr_pf, train_x_pf, train_y_pf, val_x_pf, val_y_pf, pref='[LinearRegression PF] ')\n",
    "\n",
    "ridge_pf_grid = {\"alpha\": [1.0, 10.0, 100.0, 1000.0], \"fit_intercept\": [True, False]}\n",
    "ridge_pf = search_train_eval(Ridge(random_state=seed), ridge_pf_grid, train_x_pf, train_y_pf, val_x_pf, val_y_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a869fcd7d0c1fac1d6f305b5d52afaec",
     "grade": true,
     "grade_id": "task3a-tests",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Checks for task 3a. \"\"\"\n",
    "assert var_exists('all_x_pf') and all_x_pf.shape == (17379, 679)\n",
    "assert var_exists('train_x_pf') and var_exists('train_y_pf') and train_x_pf.shape[0] == train_y_pf.shape[0]\n",
    "assert var_exists('val_x_pf') and var_exists('val_y_pf') and val_x_pf.shape[0] == val_y_pf.shape[0]\n",
    "assert var_exists('test_x_pf') and var_exists('test_y_pf') and test_x_pf.shape[0] == test_y_pf.shape[0]\n",
    "assert train_x_pf.shape[0] == 13903 and val_x_pf.shape[0] == 1738 and test_x_pf.shape == val_x_pf.shape\n",
    "assert train_x_pf.shape[1] == val_x_pf.shape[1]\n",
    "assert np.amin(train_x_pf) >= 0.0 and np.amax(train_x_pf) <= 1.0\n",
    "\n",
    "assert var_exists('ridge_nopf') and var_exists('lr_pf') and var_exists('ridge_pf')\n",
    "assert ridge_nopf.coef_.shape == (14,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5417e88ed3d4f33f7626b96ece3e8ffe",
     "grade": false,
     "grade_id": "task3b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3b] (5 points) For each of the three models, print the three most important features (coef values and name). You can use 'get_feature_names_out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6425b4f6904d3ac77fc5e34757315941",
     "grade": false,
     "grade_id": "task3b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ridge_nopf top 3 features:\n",
      "registered: coef=919.842940\n",
      "hour: coef=53.907427\n",
      "nsqrtc: coef=-36.520766\n",
      "\n",
      "lr_pf top 3 features:\n",
      "registered nsqrtc: coef=29427076.441264\n",
      "season nsqrtc: coef=-17279608.703701\n",
      "registered nsqrtc^2: coef=-15725028.916407\n",
      "\n",
      "ridge_pf top 3 features:\n",
      "registered^3: coef=-781.171044\n",
      "hour^3: coef=-727.502021\n",
      "hour registered^2: coef=561.149185\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "feat_names_nopf = np.array(features)\n",
    "feat_names_pf = polyf.get_feature_names_out(features)\n",
    "\n",
    "def print_top3(model, names, label):\n",
    "    top_idx = np.argsort(np.abs(model.coef_))[-3:][::-1]\n",
    "    print(f\"\\n{label} top 3 features:\")\n",
    "    for i in top_idx:\n",
    "        print(f\"{names[i]}: coef={model.coef_[i]:.6f}\")\n",
    "\n",
    "print_top3(ridge_nopf, feat_names_nopf, \"ridge_nopf\")\n",
    "print_top3(lr_pf, feat_names_pf, \"lr_pf\")\n",
    "print_top3(ridge_pf, feat_names_pf, \"ridge_pf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bea6b39d98f12d1f62f27148d85ec62",
     "grade": true,
     "grade_id": "task3b_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# THIS CODE CELL IS INTENTIONALLY LEFT EMPTY --- DO NOT MODIFY THIS CELL\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c62c7836558e3b4ee481de42b4f56d24",
     "grade": false,
     "grade_id": "task3c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3c] (5 points) Out of the three models, which would you use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b344b53283df484008b5ae14a68e8ae4",
     "grade": true,
     "grade_id": "task3c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "# I would choose lr_pf(Linear Regression Model with Polynomial Features)\n",
    "# It has the best validation metrics among the three models:\n",
    "# Val R^2 = 0.923 (highest), Val MSE = 2570.585 (lowest), and Val MAE = 24.583 (lowest).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "449dab32812541b0bb11bb3e3a649358",
     "grade": false,
     "grade_id": "task4-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4] (25 points) Trees and Bagging Ensembles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c85c9b2327b4e739bb17ea6c2145c1d",
     "grade": false,
     "grade_id": "task4-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's do some cleanup and sanity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a12e338911260c668247d0041d1c859",
     "grade": false,
     "grade_id": "task4-instruct-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# let's do some cleanup and discard all the polynomial features stuff.\n",
    "if var_exists('all_x_pf'):\n",
    "    del all_x_pf, train_x_pf, train_y_pf, test_x_pf, test_y_pf, val_x_pf, val_y_pf\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e0011ce50befe631de399acb915a494",
     "grade": false,
     "grade_id": "task4a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4a] (5 points) Suppose a sklearn decision tree has n nodes. How many total splits does it contain? (Hint: think of it as a CS question not an ML question. Also think about edge cases (e.g., n=0).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "695bdedb230ff2cea44d95bf364ab6a2",
     "grade": false,
     "grade_id": "task4a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here to answer by implementing the function.\n",
    "\"\"\"\n",
    "def num_dt_splits(nodes): # should return the total number of splits in a decision tree. Must return an integer value.\n",
    "    assert nodes >= 0\n",
    "    # YOUR CODE HERE\n",
    "    return max(0, nodes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da184360d058a9471fe3344d3dc64b19",
     "grade": true,
     "grade_id": "task4a-tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4a. \"\"\"\n",
    "assert var_exists('num_dt_splits')\n",
    "assert num_dt_splits(0) == 0 and num_dt_splits(1) == 0\n",
    "for i in range(0, 100):\n",
    "    nodes = np.random.randint(0, 1e8)\n",
    "    splits = num_dt_splits(nodes)\n",
    "    assert splits>=0 and splits == int(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7566934d1bdc293f09c8fb02e3e788",
     "grade": false,
     "grade_id": "cell-282724082b83b395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's train a decision tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b22fb44956e4472dc9149d8bfaa18332",
     "grade": false,
     "grade_id": "task4b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4b] (5 points) Train and evaluate two (regression) decision trees with sklearn's DecisionTreeRegressor. The first 'dtmodel' should be trained with default parameters (set the seed). The second 'dtregmodel' should be trained with the default parameters (set the seed) but a max depth of 7. Use r2_mse_mae_eval to print performance of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef9d31fa1e0b4b862b76d2ce94c3668f",
     "grade": false,
     "grade_id": "task4b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeRegressor] Train R^2: 1.000, Val  R^2: 0.970\n",
      "[DecisionTreeRegressor] Train MSE: 0.000, Val MSE: 1014.636\n",
      "[DecisionTreeRegressor] Train MAE: 0.000, Val MAE: 10.080\n",
      "[DecisionTreeRegressor max_depth=7] Train R^2: 0.955, Val  R^2: 0.957\n",
      "[DecisionTreeRegressor max_depth=7] Train MSE: 1508.853, Val MSE: 1451.577\n",
      "[DecisionTreeRegressor max_depth=7] Train MAE: 18.368, Val MAE: 18.929\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5 lines)\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtmodel = DecisionTreeRegressor(random_state=seed).fit(train_x, train_y)\n",
    "_ = r2_mse_mae_eval(dtmodel, train_x, train_y, val_x, val_y, pref='[{}] '.format(dtmodel.__class__.__name__))\n",
    "\n",
    "dtregmodel = DecisionTreeRegressor(max_depth=7,random_state=seed).fit(train_x, train_y)\n",
    "_ = r2_mse_mae_eval(dtregmodel, train_x, train_y, val_x, val_y, pref='[{} max_depth=7] '.format(dtregmodel.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee30a51e792cbe4d9a005c4d90e6acf4",
     "grade": true,
     "grade_id": "task4b-checks",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4b. \"\"\"\n",
    "assert var_exists('dtmodel') and var_exists('dtregmodel') \n",
    "assert dtmodel.tree_.max_depth >= 6 and dtregmodel.tree_.max_depth == 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9de52d5ce39f0ee93b9ea9c7ac11c9f",
     "grade": false,
     "grade_id": "task4c-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4c] (5 points) Is the regularized model overfitted? Is it better than the models trained in Tasks 2 and 3? (A few sentences suffice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff373393b63e44dd706dd02be10f635c",
     "grade": true,
     "grade_id": "task4c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "# The regularized tree (max_depth=7) does not appear overfitted because its train and validation R^2 are very close\n",
    "# (train  0.955 vs val  0.957), unlike the unregularized tree which achieves perfect train R^2 = 1.0.\n",
    "# It is also better than the models from Tasks 2 and 3, since its validation R^2 (~0.957) is higher than the\n",
    "# linear models in Task 2 (~0.845) and the polynomial/regularized linear models in Task 3 (~0.923 and ~0.896).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60d37ad914f87535f1c9bb16bb9526f7",
     "grade": false,
     "grade_id": "cell-fb9d19cf2516c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's explore bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e8dd970d6ffe798592d102494514539",
     "grade": false,
     "grade_id": "task4d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4d] (5 points) Train two ensemble models using sklearn's BaggingRegressor. Use default parameters but be sure to set the seed and set max_samples=0.5. The first ensemble 'lr_bagging' must use 'LinearRegression' as weak learners, whereas the second 'dtr_bagging' must use 'DecisionTreeRegressor' as weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16e5d3a3b91e41285e5e9f093eb1f03c",
     "grade": false,
     "grade_id": "task4d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear Regression Bagging] Train R^2: 0.841, Val  R^2: 0.845\n",
      "[Linear Regression Bagging] Train MSE: 5271.255, Val MSE: 5185.668\n",
      "[Linear Regression Bagging] Train MAE: 39.617, Val MAE: 38.498\n",
      "\n",
      "[DT Regression Bagging aka Random Forest] Train R^2: 0.989, Val  R^2: 0.982\n",
      "[DT Regression Bagging aka Random Forest] Train MSE: 378.306, Val MSE: 609.102\n",
      "[DT Regression Bagging aka Random Forest] Train MAE: 5.898, Val MAE: 8.416\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~3 lines)\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "lr_bagging = BaggingRegressor(estimator=LinearRegression(), max_samples=0.5, random_state=seed).fit(train_x, train_y)\n",
    "dtr_bagging = BaggingRegressor(estimator=DecisionTreeRegressor(), max_samples=0.5, random_state=seed).fit(train_x, train_y)\n",
    "\n",
    "_ = r2_mse_mae_eval(lr_bagging, train_x, train_y, val_x, val_y, pref='[Linear Regression Bagging] ')\n",
    "print()\n",
    "_ = r2_mse_mae_eval(dtr_bagging, train_x, train_y, val_x, val_y, pref='[DT Regression Bagging aka Random Forest] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "527ec37234f653709a3f8c57a3febf74",
     "grade": true,
     "grade_id": "task4d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4d. \"\"\"\n",
    "assert var_exists('lr_bagging') and var_exists('dtr_bagging') \n",
    "assert lr_bagging.random_state == dtr_bagging.random_state and dtr_bagging.random_state == seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1380de7303df21fa79e0942ecf785d86",
     "grade": false,
     "grade_id": "task4e-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4e] (5 points) Answer the following questions: \n",
    "### 1. Is the linear regression bagging ensemble a better model than linear regression (Task 2)? Is this expected? (We are looking for an explanation of why this approach performs the way it does.)\n",
    "### 2. How does the random forest compare to all other models in this and previous task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e515e74c59752f118ce4e0a5c383c9",
     "grade": true,
     "grade_id": "task4e_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "#\n",
    "# YOUR CODE HERE\n",
    "# 1. As seen in the experiments, the metrics are essentially the same for the bagged linear regression and the single linear regression, \n",
    "# which suggests that bagging did not provide any significant improvement for the linear model. This is likely because \n",
    "# linear regression is a low-variance model, so averaging multiple linear regressions does not reduce variance much.\n",
    "\n",
    "# 2. The random-forest-style bagging model is the best overall in my runs:\n",
    "#    Val R^2 = 0.982 (highest), Val MSE = 609.102 (lowest), Val MAE = 8.416 (lowest),\n",
    "#    which is much better than Task 2 linear models, Task 3 polynomial/ridge models, and single trees in Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
